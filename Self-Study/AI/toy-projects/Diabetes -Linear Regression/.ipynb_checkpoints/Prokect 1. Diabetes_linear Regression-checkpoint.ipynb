{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 데이터 가져오기\n",
    "(2) 모델에 입력할 데이터 X 준비하기\n",
    "(3) 모델에 예측할 데이터 y 준비하기\n",
    "(4) train 데이터와 test 데이터로 분리하기\n",
    "(5) 모델 준비하기\n",
    "(6) 손실함수 loss 정의하기\n",
    "(7) 기울기를 구하는 gradient 함수 구현하기\n",
    "(8) 하이퍼 파라미터인 학습률 설정하기\n",
    "(9) 모델 학습하기\n",
    "(10) test 데이터에 대한 성능 확인하기\n",
    "(11) 정답 데이터와 예측한 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 가져오기\n",
    "\n",
    " - sklearn.datasets의 load_diabetes.\n",
    " - diabetes의 data를 df_X에, target을 df_y에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "data=datasets.load_diabetes()\n",
    "\n",
    "df_X=data['data']\n",
    "df_y=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델에 입력할 데이터 x 준비하기, 모델에 예측할 데이터 y 준비하기\n",
    "\n",
    " - df_X에 있는 값들을 numpy array로 변환해서 저장\n",
    " - df_y에 있는 값들을 numpy array로 변환해서 저장\n",
    " \n",
    " - X와 y 데이터를 각각 train 데이터와 test 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_X=np.array(df_X)\n",
    "df_y=np.array(df_y)\n",
    "\n",
    "train_X,test_X,train_y,test_y=train_test_split(df_X,df_y,test_size=0.2,random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.모델 준비하기\n",
    "\n",
    " - 입력 데이터 개수에 맞는 가중치 W와 b를 준비\n",
    " - 모델 함수를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.random.rand(10)\n",
    "b=np.random.rand()\n",
    "\n",
    "def model(X,w,b):\n",
    "    y=0\n",
    "    for i in range(10):\n",
    "        y +=X[:,i] * w[i]\n",
    "    y +=b\n",
    "    \n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1403562941112736"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=sum(train_X[0]*w) +b\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07247629575538031"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=0\n",
    "for i in range(10):\n",
    "   y +=train_X[0][i] * w[i] \n",
    "y+=b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 손실함수 정의\n",
    " - 손실함수를 MSE 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(y,y_pred):\n",
    "    loss= (y-ypred)**2 / len(y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 기울기 구하는 Gradient 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 하이퍼 파라미터 Learning rate 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 학습하기\n",
    "\n",
    "- 정의된 손실함수와 기울기 함수로 모델을 학습\n",
    "- loss값이 충분히 떨어질 때까지 학습을 진행.\n",
    "- 입력하는 데이터인 X에 들어가는 특성 컬럼들을 몇 개 빼도 OK. 다양한 데이터로 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test 데이터에 대한 성능 확인 및 정답 데이터와 예측 데이터 시각화\n",
    "\n",
    " -x축에는 X 데이터의 첫 번째 컬럼을, y축에는 정답인 target 데이터를 넣어서 모델이 예측한 데이터를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
